"""
Script principal pour l'ex√©cution compl√®te de l'ETL
"""
import sys
import os
import logging

# Configuration des chemins
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# Import des modules
# On utilise try/except pour g√©rer les cas o√π les scripts s'appeleraient diff√©remment
try:
    from scripts.extract_data import DataExtractor
    from scripts.transform_data import DataTransformer
    from scripts.load_dwh import DWLoader
except ImportError:
    # Fallback si on lance depuis le dossier racine
    from extract_data import DataExtractor
    from transform_data import DataTransformer
    from load_dwh import DWLoader

# Configuration du Logging
log_dir = os.path.join(parent_dir, 'data')
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(log_dir, 'etl_log.log'), mode='w', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def run_etl():
    """Ex√©cution compl√®te du pipeline ETL"""
    logger.info("=" * 60)
    logger.info("üöÄ D√âMARRAGE DU PIPELINE ETL (NORTHWIND)")
    logger.info("=" * 60)
    
    try:
        # ---------------------------------------------------------
        # √âtape 1: Extraction
        # ---------------------------------------------------------
        logger.info("\nüì• √âTAPE 1: EXTRACTION (Source -> Raw)")
        extractor = DataExtractor()
        # On utilise extract_from_access car c'est la m√©thode qu'on a valid√©e ensemble
        success_extract = extractor.extract_from_access()
        
        if not success_extract:
            logger.error("‚ùå √âchec de l'extraction. Arr√™t du pipeline.")
            return False
        
        # ---------------------------------------------------------
        # √âtape 2: Transformation
        # ---------------------------------------------------------
        logger.info("\n‚öôÔ∏è √âTAPE 2: TRANSFORMATION (Raw -> Processed)")
        transformer = DataTransformer()
        transformer.transform_all()
        # transform_all ne retourne rien dans notre version, s'il ne plante pas, c'est bon.
        
        # ---------------------------------------------------------
        # √âtape 3: Chargement
        # ---------------------------------------------------------
        logger.info("\nüíæ √âTAPE 3: CHARGEMENT (Processed -> Warehouse)")
        loader = DWLoader()
        # On appelle load_local() car nous avons configur√© le mode sans serveur
        loader.load_local()
        
        logger.info("=" * 60)
        logger.info("‚úÖ PIPELINE ETL TERMIN√â AVEC SUCC√àS")
        logger.info("=" * 60)
        
        # G√©n√©rer un rapport de synth√®se
        generate_summary()
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur critique dans le pipeline ETL: {e}", exc_info=True)
        return False

def generate_summary():
    """G√©n√®re un rapport de synth√®se mis √† jour"""
    summary = """
    ============================
    RAPPORT DE SYNTH√àSE ETL
    ============================
    
    üìä DONN√âES TRAIT√âES:
    
    1. Extraction:
       - Source: Microsoft Access / Excel
       - Destination: CSV (Raw)
       - Statut: OK
    
    2. Transformation:
       - Nettoyage: Suppression espaces, formatage dates
       - Mod√©lisation: Star Schema (√âtoile)
       - Dimensions: DimDate, DimClient, DimEmployee, DimProduct
       - Faits: FactSales
    
    3. Chargement (Warehouse):
       - Type: Hybride (Fichiers CSV + Base SQLite locale)
       - Localisation: /data/warehouse/
       - Fichier DB: northwind_dwh.db
    
    üéØ PR√äT POUR ANALYSE:
    
    - Les donn√©es sont pr√™tes pour les Notebooks.
    - Ouvrez 'notebooks/dashboard_analysis.ipynb'.
    """
    
    print(summary)
    
    # Sauvegarder le rapport
    report_path = os.path.join(parent_dir, 'data', 'warehouse', 'etl_summary.txt')
    try:
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(summary)
    except Exception as e:
        logger.warning(f"Impossible d'√©crire le rapport texte : {e}")

if __name__ == "__main__":
    success = run_etl()
    if success:
        print("\nüéâ Pipeline ETL ex√©cut√© avec succ√®s!")
    else:
        print("\n‚ùå Pipeline ETL √©chou√©. Consultez data/etl_log.log")
        